{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "크롤링 코드 .ipynb의 사본",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanzerine/SongsWLove.github.io/blob/main/%ED%81%AC%EB%A1%A4%EB%A7%81_%EC%BD%94%EB%93%9C\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08dBQoumd1TD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "3c35ec82-93aa-419e-ad65-57356618ea64"
      },
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import requests\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome('C:/Users/DLee/Downloads/chromedriver_win32 (2)/chromedriver.exe')  #본인 드라이버 위치로 수정해서 쓰세요~\n",
        "# song id, url, 제목, 아티스트 크롤링\n",
        "\n",
        "\n",
        "\n",
        "# 1984년 ~ 1989년 각각 탑 10 노래들을 모아서 80년대 차트로 설정. songdetail 페이지로 가는 url 모아서 리스트 만들기\n",
        "list_80s = []\n",
        "\n",
        "for x in range(1984,1990):\n",
        "    year = x\n",
        "    url = 'https://www.melon.com/chart/age/index.htm?chartType=YE&chartGenre=KPOP&chartDate=' + str(year)\n",
        "    driver.get(url)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html,'html.parser')\n",
        "\n",
        "    for idx, song, singer in zip(range(1, 11), soup.select('tbody a[href*=playSong]'), soup.select('.rank02')) :\n",
        "        title = song.text\n",
        "        artist = singer.find('span').text\n",
        "        js = song['href']\n",
        "        matched = re.search(r\"'(\\d+)'\\);\", js)\n",
        "        if matched:\n",
        "            song_id = matched.group(1)\n",
        "            song_url = \"http://www.melon.com/song/detail.htm?songId=\" + song_id\n",
        "            print(str(idx)+'.', title, '-', artist, song_url)\n",
        "            list_80s.append(song_url)\n",
        "\n",
        "\n",
        " # 1990년 ~ 1999년 각각 탑 10 노래들을 모아서 90년대 차트로 설정. songdetail 페이지로 가는 url 모아서 리스트 만들기\n",
        "list_90s = []\n",
        "\n",
        "for x in range(1990,2000):\n",
        "    year = x\n",
        "    url = 'https://www.melon.com/chart/age/index.htm?chartType=YE&chartGenre=KPOP&chartDate=' + str(year)\n",
        "    driver.get(url)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html,'html.parser')\n",
        "\n",
        "    for idx, song, singer in zip(range(1, 11), soup.select('tbody a[href*=playSong]'), soup.select('.rank02')) :\n",
        "        title = song.text\n",
        "        artist = singer.find('span').text\n",
        "        js = song['href']\n",
        "        matched = re.search(r\"'(\\d+)'\\);\", js)\n",
        "        if matched:\n",
        "            song_id = matched.group(1)\n",
        "            song_url = \"http://www.melon.com/song/detail.htm?songId=\" + song_id\n",
        "            print(str(idx)+'.', title, '-', artist, song_url)\n",
        "            list_90s.append(song_url)\n",
        "\n",
        "\n",
        "# 2000년 ~ 2009년 각각 탑 10 노래들을 모아서 00년대 차트로 설정. songdetail 페이지로 가는 url 모아서 리스트 만들기\n",
        "list_00s = []\n",
        "\n",
        "for x in range(2000,2010):\n",
        "    year = x\n",
        "    url = 'https://www.melon.com/chart/age/index.htm?chartType=YE&chartGenre=KPOP&chartDate=' + str(year)\n",
        "    driver.get(url)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html,'html.parser')\n",
        "\n",
        "    for idx, song, singer in zip(range(1, 11), soup.select('tbody a[href*=playSong]'), soup.select('.rank02')) :\n",
        "        title = song.text\n",
        "        artist = singer.find('span').text\n",
        "        js = song['href']\n",
        "        matched = re.search(r\"'(\\d+)'\\);\", js)\n",
        "        if matched:\n",
        "            song_id = matched.group(1)\n",
        "            song_url = \"http://www.melon.com/song/detail.htm?songId=\" + song_id\n",
        "            print(str(idx)+'.', title, '-', artist, song_url)\n",
        "            list_00s.append(song_url)           \n",
        "\n",
        "# 2010년 ~ 2019년 각각 탑 10 노래들을 모아서 10년대 차트로 설정. songdetail 페이지로 가는 url 모아서 리스트 만들기\n",
        "list_10s = []\n",
        "\n",
        "for x in range(2010,2020):\n",
        "    year = x\n",
        "    url = 'https://www.melon.com/chart/age/index.htm?chartType=YE&chartGenre=KPOP&chartDate=' + str(year)\n",
        "    driver.get(url)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html,'html.parser')\n",
        "\n",
        "    for idx, song, singer in zip(range(1, 11), soup.select('tbody a[href*=playSong]'), soup.select('.rank02')) :\n",
        "        title = song.text\n",
        "        artist = singer.find('span').text\n",
        "        js = song['href']\n",
        "        matched = re.search(r\"'(\\d+)'\\);\", js)\n",
        "        if matched:\n",
        "            song_id = matched.group(1)\n",
        "            song_url = \"http://www.melon.com/song/detail.htm?songId=\" + song_id\n",
        "            print(str(idx)+'.', title, '-', artist, song_url)\n",
        "            list_10s.append(song_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f9681332f00e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D-kRvbNeKzS"
      },
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import requests\n",
        "driver = webdriver.Chrome('C:/Users/CSYUN/Desktop/CSYUN/2020/2020-2/paic/pjt/chromedriver/chromedriver.exe') #드라이버 주소 본인걸로 수정하세요!\n",
        "# 위에서 얻은 url리스트로 각각 들어가서 가사 크롤링\n",
        "\n",
        "lyric_80s = []\n",
        "for links in list_80s :\n",
        "    url = links\n",
        "    driver.get(url)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html,'html.parser')\n",
        "    lyric_80s.append(soup.select('#d_video_summary')[0].text.replace(\"\t\t\t\t\t\t\t\",\"\"))\n",
        "\n",
        "lyric_80s_final = []\n",
        "for items in lyric_80s :\n",
        "    lyric_80s_final.append(items.replace(\"\\n\",' ').replace(\"\\t\",'').replace(\"\\xa0\", \" \"))\n",
        "\n",
        "\n",
        "lyric_90s = []\n",
        "for links in list_90s :\n",
        "    url = links\n",
        "    driver.get(url)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html,'html.parser')\n",
        "    lyric_90s.append(soup.select('#d_video_summary')[0].text.replace(\"\t\t\t\t\t\t\t\",\"\"))\n",
        "\n",
        "lyric_90s_final = []\n",
        "for items in lyric_90s :\n",
        "    lyric_90s_final.append(items.replace(\"\\n\",' ').replace(\"\\t\",'').replace(\"\\xa0\", \" \"))\n",
        "\n",
        "\n",
        "lyric_00s = []\n",
        "for links in list_00s :\n",
        "    url = links\n",
        "    driver.get(url)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html,'html.parser')\n",
        "    lyric_00s.append(soup.select('#d_video_summary')[0].text.replace(\"\t\t\t\t\t\t\t\",\"\"))\n",
        "\n",
        "lyric_00s_final = []\n",
        "for items in lyric_00s :\n",
        "    lyric_00s_final.append(items.replace(\"\\n\",' ').replace(\"\\t\",'').replace(\"\\xa0\", \" \"))\n",
        "\n",
        "\n",
        "lyric_10s = []\n",
        "for links in list_10s :\n",
        "    url = links\n",
        "    driver.get(url)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html,'html.parser')\n",
        "    lyric_10s.append(soup.select('#d_video_summary')[0].text.replace(\"\t\t\t\t\t\t\t\",\"\"))\n",
        "\n",
        "lyric_10s_final = []\n",
        "for items in lyric_10s :\n",
        "    lyric_10s_final.append(items.replace(\"\\n\",' ').replace(\"\\t\",'').replace(\"\\xa0\", \" \"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git    #띄어쓰기 패키지\n",
        "from pykospacing import spacing\n",
        "\n",
        "\n",
        "\n",
        "fin_80s = []\n",
        "for items in lyric_80s_final :\n",
        "    sent = items\n",
        "    new_sent = sent.replace(\" \", '') \n",
        "    kospacing_sent = spacing(new_sent)\n",
        "    fin_80s.append(kospacing_sent)\n",
        "    \n",
        "fin_90s = []\n",
        "for items in lyric_90s_final :\n",
        "    sent = items\n",
        "    new_sent = sent.replace(\" \", '') \n",
        "    kospacing_sent = spacing(new_sent)\n",
        "    fin_90s.append(kospacing_sent)\n",
        "    \n",
        "fin_00s = []\n",
        "for items in lyric_00s_final :\n",
        "    sent = items\n",
        "    new_sent = sent.replace(\" \", '') \n",
        "    kospacing_sent = spacing(new_sent)\n",
        "    fin_00s.append(kospacing_sent)\n",
        "    \n",
        "fin_10s = []\n",
        "for items in lyric_10s_final :\n",
        "    sent = items\n",
        "    new_sent = sent.replace(\" \", '') \n",
        "    kospacing_sent = spacing(new_sent)\n",
        "    fin_10s.append(kospacing_sent)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}